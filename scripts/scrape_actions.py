#!/usr/bin/env python3
"""
GitHub Actions æ—¥å¿—æŠ“å–è„šæœ¬ - ä½¿ç”¨ Playwright
"""

import json
import sys
from playwright.sync_api import sync_playwright

REPO_OWNER = "wjllance"
REPO_NAME = "standx-cli"

def scrape_latest_action():
    """æŠ“å–æœ€æ–°çš„ GitHub Actions è¿è¡Œç»“æœ"""
    
    with sync_playwright() as p:
        # å¯åŠ¨ headless æµè§ˆå™¨
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.0'
        )
        page = context.new_page()
        
        try:
            # è®¿é—® Actions é¡µé¢
            url = f"https://github.com/{REPO_OWNER}/{REPO_NAME}/actions"
            print(f"ğŸŒ è®¿é—®: {url}")
            page.goto(url, wait_until="networkidle")
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            page.wait_for_timeout(3000)
            
            # æˆªå›¾ä¿å­˜
            page.screenshot(path="/tmp/github_actions_overview.png")
            print("ğŸ“¸ å·²ä¿å­˜æˆªå›¾: /tmp/github_actions_overview.png")
            
            # è·å–æœ€æ–°çš„å·¥ä½œæµè¿è¡Œ
            result = {
                "repo": f"{REPO_OWNER}/{REPO_NAME}",
                "timestamp": page.evaluate("() => new Date().toISOString()"),
                "runs": []
            }
            
            # æŸ¥æ‰¾å·¥ä½œæµè¿è¡Œåˆ—è¡¨
            # GitHub çš„é¡µé¢ç»“æ„å¯èƒ½å˜åŒ–ï¼Œè¿™é‡Œä½¿ç”¨å¤šç§é€‰æ‹©å™¨å°è¯•
            selectors = [
                "[data-testid='workflow-run']",
                ".workflow-run",
                "[data-testid='run-item']",
                ".ActionList-item",
                "article[data-testid]"
            ]
            
            runs = []
            for selector in selectors:
                try:
                    elements = page.locator(selector).all()
                    if elements:
                        print(f"âœ… æ‰¾åˆ° {len(elements)} ä¸ªè¿è¡Œè®°å½• (ä½¿ç”¨é€‰æ‹©å™¨: {selector})")
                        runs = elements[:5]  # åªå–å‰5ä¸ª
                        break
                except:
                    continue
            
            if not runs:
                print("âš ï¸ æœªæ‰¾åˆ°å·¥ä½œæµè¿è¡Œè®°å½•ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ...")
                # å¤‡ç”¨ï¼šç›´æ¥è·å–é¡µé¢æ–‡æœ¬
                page_text = page.content()
                if "success" in page_text.lower():
                    result["detected_status"] = "success"
                elif "failure" in page_text.lower() or "failed" in page_text.lower():
                    result["detected_status"] = "failure"
                
                # ä¿å­˜ HTML ç”¨äºåˆ†æ
                with open("/tmp/github_actions_page.html", "w") as f:
                    f.write(page_text)
                print("ğŸ“ å·²ä¿å­˜é¡µé¢ HTML: /tmp/github_actions_page_page.html")
            
            # è§£ææ¯ä¸ªè¿è¡Œè®°å½•
            for i, run in enumerate(runs):
                try:
                    run_data = {"index": i}
                    
                    # å°è¯•è·å–çŠ¶æ€
                    try:
                        # æŸ¥æ‰¾çŠ¶æ€å›¾æ ‡
                        status_selectors = [
                            "[data-testid='run-status']",
                            ".status-icon",
                            "svg.octicon-check",
                            "svg.octicon-x",
                            ".octicon-check",
                            ".octicon-x",
                            "[aria-label*='success' i]",
                            "[aria-label*='fail' i]"
                        ]
                        
                        for sel in status_selectors:
                            try:
                                icon = run.locator(sel).first
                                if icon.count() > 0:
                                    aria = icon.get_attribute("aria-label") or ""
                                    if "success" in aria.lower() or "check" in sel:
                                        run_data["status"] = "success"
                                        break
                                    elif "fail" in aria.lower() or "x" in sel:
                                        run_data["status"] = "failure"
                                        break
                            except:
                                continue
                        
                        if "status" not in run_data:
                            run_data["status"] = "unknown"
                            
                    except Exception as e:
                        run_data["status_error"] = str(e)
                    
                    # å°è¯•è·å–æ ‡é¢˜/æäº¤ä¿¡æ¯
                    try:
                        title_selectors = ["h3", ".commit-message", "a.Link--primary", ".d-flex a"]
                        for sel in title_selectors:
                            try:
                                title_elem = run.locator(sel).first
                                if title_elem.count() > 0:
                                    run_data["title"] = title_elem.inner_text()[:100]
                                    break
                            except:
                                continue
                    except:
                        pass
                    
                    # å°è¯•è·å–æ—¶é—´
                    try:
                        time_elem = run.locator("time, relative-time").first
                        if time_elem.count() > 0:
                            run_data["time"] = time_elem.get_attribute("datetime") or time_elem.inner_text()
                    except:
                        pass
                    
                    result["runs"].append(run_data)
                    
                except Exception as e:
                    result["runs"].append({"index": i, "error": str(e)})
            
            # è·å–æœ€æ–°è¿è¡Œçš„è¯¦ç»†é¡µé¢
            if result["runs"]:
                latest = result["runs"][0]
                print(f"\nğŸ“Š æœ€æ–°è¿è¡ŒçŠ¶æ€: {latest.get('status', 'unknown')}")
                
                # ç‚¹å‡»ç¬¬ä¸€ä¸ªè¿è¡ŒæŸ¥çœ‹è¯¦æƒ…
                try:
                    first_run_link = page.locator("a[href*='/actions/runs/']").first
                    if first_run_link.count() > 0:
                        href = first_run_link.get_attribute("href")
                        if href:
                            result["latest_run_url"] = f"https://github.com{href}"
                            print(f"ğŸ”— æœ€æ–°è¿è¡Œé“¾æ¥: {result['latest_run_url']}")
                except:
                    pass
            
            # è¾“å‡ºç»“æœ
            print("\n" + "="*50)
            print("ğŸ“‹ æŠ“å–ç»“æœ:")
            print("="*50)
            print(json.dumps(result, indent=2, ensure_ascii=False))
            
            return result
            
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            # å‡ºé”™æ—¶æˆªå›¾
            try:
                page.screenshot(path="/tmp/github_actions_error.png")
                print("ğŸ“¸ é”™è¯¯æˆªå›¾å·²ä¿å­˜: /tmp/github_actions_error.png")
            except:
                pass
            raise
            
        finally:
            browser.close()

def scrape_specific_run(run_id):
    """æŠ“å–ç‰¹å®šè¿è¡Œçš„è¯¦ç»†æ—¥å¿—"""
    
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        )
        page = context.new_page()
        
        try:
            url = f"https://github.com/{REPO_OWNER}/{REPO_NAME}/actions/runs/{run_id}"
            print(f"ğŸŒ è®¿é—®è¿è¡Œè¯¦æƒ…: {url}")
            page.goto(url, wait_until="networkidle")
            page.wait_for_timeout(3000)
            
            # æˆªå›¾
            page.screenshot(path=f"/tmp/github_actions_run_{run_id}.png")
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: /tmp/github_actions_run_{run_id}.png")
            
            result = {
                "run_id": run_id,
                "url": url,
                "jobs": []
            }
            
            # æŸ¥æ‰¾ä½œä¸šçŠ¶æ€
            job_selectors = [
                "[data-testid='job-log']",
                ".job-item",
                ".check-run-item",
                "[data-testid='check-run']"
            ]
            
            for selector in job_selectors:
                try:
                    jobs = page.locator(selector).all()
                    if jobs:
                        print(f"âœ… æ‰¾åˆ° {len(jobs)} ä¸ªä½œä¸š")
                        for job in jobs:
                            try:
                                job_name = job.locator("h3, .job-name, .text-bold").first.inner_text()
                                result["jobs"].append({"name": job_name[:50]})
                            except:
                                pass
                        break
                except:
                    continue
            
            # è·å–é¡µé¢ä¸Šçš„çŠ¶æ€æ–‡æœ¬
            page_text = page.inner_text("body")
            if "succeeded" in page_text.lower() or "completed" in page_text.lower():
                result["overall_status"] = "success"
            elif "failed" in page_text.lower() or "failure" in page_text.lower():
                result["overall_status"] = "failure"
            else:
                result["overall_status"] = "unknown"
            
            print("\n" + "="*50)
            print("ğŸ“‹ è¿è¡Œè¯¦æƒ…:")
            print("="*50)
            print(json.dumps(result, indent=2, ensure_ascii=False))
            
            return result
            
        finally:
            browser.close()

if __name__ == "__main__":
    print("ğŸ” GitHub Actions æ—¥å¿—æŠ“å–å·¥å…·")
    print("="*50)
    
    # æŠ“å–æœ€æ–°çŠ¶æ€
    result = scrape_latest_action()
    
    # å¦‚æœæœ‰è¿è¡Œè®°å½•ï¼ŒæŠ“å–ç¬¬ä¸€ä¸ªçš„è¯¦æƒ…
    if result and result.get("runs"):
        latest = result["runs"][0]
        if latest.get("status") == "failure":
            print("\nâš ï¸ æ£€æµ‹åˆ°å¤±è´¥ï¼Œå°è¯•è·å–è¯¦ç»†æ—¥å¿—...")
            # ä» URL æå– run_id
            if result.get("latest_run_url"):
                run_id = result["latest_run_url"].split("/runs/")[-1].split("/")[0]
                if run_id.isdigit():
                    scrape_specific_run(run_id)
    
    print("\nâœ… å®Œæˆ!")
